{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"cDUni0TkGHjR","colab_type":"code","colab":{}},"source":["# !pip install bounter\n","import string\n","from bounter import bounter\n","\n","def remove_punctuation(sentence):\n","  return sentence.translate(str.maketrans('','', string.punctuation))\n","\n","############################ cleaned.txt -- true Singlish strings ##############################\n","\n","raw_f = open(\"smsCorpus_Line_by_line_SG_only.txt\", mode = 'r')\n","raw_data = raw_f.readlines()\n","# clean data and output a file with data after processing\n","for row in raw_data:\n","  f = open(\"cleaned.txt\", \"a\")\n","  f.write(remove_punctuation(row.rstrip().lower()) + \"\\n\")\n","  f.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwdgEBiFeN5b","colab_type":"code","colab":{}},"source":["############################# markov_chain_50.txt three_grams ##############################\n","\n","# a public list\n","three_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2)\n","      three_grams.append(combination)\n","\n","three_grams_set = set(three_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"markov_chain_50.txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2)])\n","\n","duplicated_counter = 0\n","\n","for three_gram in three_grams_set:\n","  if counts[three_gram] != 0:\n","    duplicated_counter += counts[three_gram]\n","    print(three_gram, counts[three_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fh4piXoptZ8d","colab_type":"code","colab":{}},"source":["############################# result (RNN, Cindy, based on 3000).txt three_grams ##############################\n","\n","# a public list\n","three_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2)\n","      three_grams.append(combination)\n","\n","three_grams_set = set(three_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2)])\n","\n","duplicated_counter = 0\n","\n","for three_gram in three_grams_set:\n","  if counts[three_gram] != 0:\n","    duplicated_counter += counts[three_gram]\n","    print(three_gram, counts[three_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1Sc6KxPeEhhl","colab":{}},"source":["##################### result (RNN, Cindy, based on 3000, word-tknize).txt three_grams #####################\n","\n","# a public list\n","three_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2)\n","      three_grams.append(combination)\n","\n","three_grams_set = set(three_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000, word-tknize).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2)])\n","\n","duplicated_counter = 0\n","\n","for three_gram in three_grams_set:\n","  if counts[three_gram] != 0:\n","    duplicated_counter += counts[three_gram]\n","    print(three_gram, counts[three_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3opflpb4Kzuv","colab":{}},"source":["################################### LSTM three_grams ####################################\n","\n","# a public list\n","three_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2)\n","      three_grams.append(combination)\n","\n","three_grams_set = set(three_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result_LSTM_Cindy_50.txt\", mode = 'r', encoding = \"ISO-8859-1\")\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-2)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2)])\n","\n","duplicated_counter = 0\n","\n","for three_gram in three_grams_set:\n","  if counts[three_gram] != 0:\n","    duplicated_counter += counts[three_gram]\n","    print(three_gram, counts[three_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVliHyo7jDXA","colab_type":"code","colab":{}},"source":["############################# markov_chain_50.txt four_grams ##############################\n","\n","# a public list\n","four_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)\n","      four_grams.append(combination)\n","\n","four_grams_set = set(four_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"markov_chain_50.txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)])\n","\n","duplicated_counter = 0\n","\n","for four_gram in four_grams_set:\n","  if counts[four_gram] != 0:\n","    duplicated_counter += counts[four_gram]\n","    print(four_gram, counts[four_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lu8VQ6xnty96","colab_type":"code","colab":{}},"source":["############################# result (RNN, Cindy, based on 3000).txt four_grams ##############################\n","\n","# a public list\n","four_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)\n","      four_grams.append(combination)\n","\n","four_grams_set = set(four_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)])\n","\n","duplicated_counter = 0\n","\n","for four_gram in four_grams_set:\n","  if counts[four_gram] != 0:\n","    duplicated_counter += counts[four_gram]\n","    print(four_gram, counts[four_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GJh4EVlPE8Cy","colab":{}},"source":["##################### result (RNN, Cindy, based on 3000, word-tknize).txt four_grams #####################\n","\n","# a public list\n","four_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)\n","      four_grams.append(combination)\n","\n","four_grams_set = set(four_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000, word-tknize).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)])\n","\n","duplicated_counter = 0\n","\n","for four_gram in four_grams_set:\n","  if counts[four_gram] != 0:\n","    duplicated_counter += counts[four_gram]\n","    print(four_gram, counts[four_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"muPQfgQPK-d0","colab":{}},"source":["#################################### LSTM four_grams #######################################\n","\n","# a public list\n","four_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)\n","      four_grams.append(combination)\n","\n","four_grams_set = set(four_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result_LSTM_Cindy_50.txt\", mode = 'r', encoding = \"ISO-8859-1\")\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-3)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3)])\n","\n","duplicated_counter = 0\n","\n","for four_gram in four_grams_set:\n","  if counts[four_gram] != 0:\n","    duplicated_counter += counts[four_gram]\n","    print(four_gram, counts[four_gram])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k96B2idXj7Gt","colab_type":"code","colab":{}},"source":["############################# markov_chain_50.txt five_grams ##############################\n","\n","# a public list\n","five_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)\n","      five_grams.append(combination)\n","\n","five_grams_set = set(five_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"markov_chain_50.txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)])\n","\n","duplicated_counter = 0\n","\n","for five_grams in five_grams_set:\n","  if counts[five_grams] != 0:\n","    duplicated_counter += counts[five_grams]\n","    print(five_grams, counts[five_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-Uka8KSuRI-","colab_type":"code","colab":{}},"source":["############################# result (RNN, Cindy, based on 3000).txt five_grams ##############################\n","\n","# a public list\n","five_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)\n","      five_grams.append(combination)\n","\n","five_grams_set = set(five_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)])\n","\n","duplicated_counter = 0\n","\n","for five_grams in five_grams_set:\n","  if counts[five_grams] != 0:\n","    duplicated_counter += counts[five_grams]\n","    print(five_grams, counts[five_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"geD-tKRxFHj0","colab":{}},"source":["##################### result (RNN, Cindy, based on 3000, word-tknize).txt five_grams #####################\n","\n","# a public list\n","five_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)\n","      five_grams.append(combination)\n","\n","five_grams_set = set(five_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000, word-tknize).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)])\n","\n","duplicated_counter = 0\n","\n","for five_grams in five_grams_set:\n","  if counts[five_grams] != 0:\n","    duplicated_counter += counts[five_grams]\n","    print(five_grams, counts[five_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c65-gSLVLGY1","colab":{}},"source":["################################## LSTM five_grams ##################################\n","\n","# a public list\n","five_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)\n","      five_grams.append(combination)\n","\n","five_grams_set = set(five_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result_LSTM_Cindy_50.txt\", mode = 'r', encoding = \"ISO-8859-1\")\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-4)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4)])\n","\n","duplicated_counter = 0\n","\n","for five_grams in five_grams_set:\n","  if counts[five_grams] != 0:\n","    duplicated_counter += counts[five_grams]\n","    print(five_grams, counts[five_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HqbCAdduZGK","colab_type":"code","colab":{}},"source":["############################# markov_chain_50.txt six_grams ##############################\n","\n","# a public list\n","six_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)\n","      six_grams.append(combination)\n","\n","six_grams_set = set(six_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"markov_chain_50.txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)])\n","\n","duplicated_counter = 0\n","\n","for six_grams in six_grams_set:\n","  if counts[six_grams] != 0:\n","    duplicated_counter += counts[six_grams]\n","    print(six_grams, counts[six_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_l90uP3-k4_G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"754f9e71-d5db-4b1d-8194-b626c5e26732","executionInfo":{"status":"ok","timestamp":1575863936965,"user_tz":300,"elapsed":1035,"user":{"displayName":"Yuzhou Guo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBYSTmhSlrZCI0TmxnthwK0iI8WYf56rIfw-4nq=s64","userId":"09274495770188460484"}}},"source":["############################# result (RNN, Cindy, based on 3000).txt six_grams ##############################\n","\n","# a public list\n","six_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)\n","      six_grams.append(combination)\n","\n","six_grams_set = set(six_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)])\n","\n","duplicated_counter = 0\n","\n","for six_grams in six_grams_set:\n","  if counts[six_grams] != 0:\n","    duplicated_counter += counts[six_grams]\n","    print(six_grams, counts[six_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Compare to data given, the duplication percentage is  0.0\n","Output duplication percentage is  0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XvNAfM4NFj7q","colab":{}},"source":["##################### result (RNN, Cindy, based on 3000, word-tknize).txt six_grams #########################\n","\n","# a public list\n","six_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)\n","      six_grams.append(combination)\n","\n","six_grams_set = set(six_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result (RNN, Cindy, based on 3000, word-tknize).txt\", mode = 'r')\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)])\n","\n","duplicated_counter = 0\n","\n","for six_grams in six_grams_set:\n","  if counts[six_grams] != 0:\n","    duplicated_counter += counts[six_grams]\n","    print(six_grams, counts[six_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dcfuEjzuLQaU","colab":{}},"source":["##################################### LSTM six_grams #########################################\n","\n","# a public list\n","six_grams = [] \n","\n","clean_f = open(\"cleaned.txt\", mode = 'r')\n","cleaned = clean_f.readlines()\n","\n","for line in cleaned:\n","  removed_slash = line.strip(\"\\n\")\n","  word_set = removed_slash.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      combination = dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)\n","      six_grams.append(combination)\n","\n","six_grams_set = set(six_grams)\n","\n","counts = bounter(size_mb=1024)  # use at most 1 GB of RAM\n","\n","f = open(\"result_LSTM_Cindy_50.txt\", mode = 'r', encoding = \"ISO-8859-1\")\n","storage = f.readlines()\n","\n","for line in storage:\n","  clean = line.strip(\"\\n\")\n","  word_set = clean.split(\" \")\n","  dic = {} # get a dictionary ready\n","  for index, word in enumerate(word_set):\n","    dic[index] = word # throw into the dic\n","  for i in range(len(dic)):\n","    if(i < (len(dic)-5)):\n","      counts.update([dic.get(i) + dic.get(i+1) + dic.get(i+2) + dic.get(i+3) + dic.get(i+4) + dic.get(i+5)])\n","\n","duplicated_counter = 0\n","\n","for six_grams in six_grams_set:\n","  if counts[six_grams] != 0:\n","    duplicated_counter += counts[six_grams]\n","    print(six_grams, counts[six_grams])\n","\n","print(\"Compare to data given, the duplication percentage is \", duplicated_counter/counts.total()*100)\n","print(\"Output duplication percentage is \", (counts.total() - counts.cardinality())/counts.total()*100)"],"execution_count":0,"outputs":[]}]}